{
    "anthropic_claude_2.0": {
        "internal_model_id": "anthropic_claude_2.0",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "anthropic_claude_2.1": {
        "internal_model_id": "anthropic_claude_2.1",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "anthropic_claude_3.5_haiku": {
        "internal_model_id": "anthropic_claude_3.5_haiku",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "anthropic_claude_3.5_sonnet": {
        "internal_model_id": "anthropic_claude_3.5_sonnet",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "anthropic_claude_3_haiku": {
        "internal_model_id": "anthropic_claude_3_haiku",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "anthropic_claude_3_opus": {
        "internal_model_id": "anthropic_claude_3_opus",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "anthropic_claude_3_sonnet": {
        "internal_model_id": "anthropic_claude_3_sonnet",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "deepseek_llama_8b": {
        "internal_model_id": "deepseek_llama_8b",
        "hf_model_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
        "hf_model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "deepseek_qwen_1.5b": {
        "internal_model_id": "deepseek_qwen_1.5b",
        "hf_model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "hf_model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
        "open / closed source": "Open",
        "parameter count": "1,500,000,000",
        "is a reasoning model?": "False"
    },
    "deepseek_qwen_14b": {
        "internal_model_id": "deepseek_qwen_14b",
        "hf_model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "hf_model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "open / closed source": "Open",
        "parameter count": "14,000,000,000",
        "is a reasoning model?": "False"
    },
    "deepseek_qwen_32b": {
        "internal_model_id": "deepseek_qwen_32b",
        "hf_model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "hf_model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "open / closed source": "Open",
        "parameter count": "32,000,000,000",
        "is a reasoning model?": "False"
    },
    "deepseek_qwen_7b": {
        "internal_model_id": "deepseek_qwen_7b",
        "hf_model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "hf_model_url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "open / closed source": "Open",
        "parameter count": "7,000,000,000",
        "is a reasoning model?": "False"
    },
    "deepseek_v2_16b": {
        "internal_model_id": "deepseek_v2_16b",
        "hf_model_id": "deepseek-ai/DeepSeek-V2-Lite",
        "hf_model_url": "https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite",
        "open / closed source": "Open",
        "parameter count": "16,000,000,000",
        "is a reasoning model?": "False"
    },
    "falcon3_10b": {
        "internal_model_id": "falcon3_10b",
        "hf_model_id": "tiiuae/Falcon3-10B-Instruct",
        "hf_model_url": "https://huggingface.co/tiiuae/Falcon3-10B-Instruct",
        "open / closed source": "Open",
        "parameter count": "10,000,000,000",
        "is a reasoning model?": "False"
    },
    "falcon3_3b": {
        "internal_model_id": "falcon3_3b",
        "hf_model_id": "tiiuae/Falcon3-3B-Instruct",
        "hf_model_url": "https://huggingface.co/tiiuae/Falcon3-3B-Instruct",
        "open / closed source": "Open",
        "parameter count": "3,000,000,000",
        "is a reasoning model?": "False"
    },
    "falcon3_7b": {
        "internal_model_id": "falcon3_7b",
        "hf_model_id": "tiiuae/falcon-7b-instruct",
        "hf_model_url": "https://huggingface.co/tiiuae/falcon-7b-instruct",
        "open / closed source": "Open",
        "parameter count": "7,000,000,000",
        "is a reasoning model?": "False"
    },
    "gemini_2_flash_lite": {
        "internal_model_id": "gemini_2_flash_lite",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "gemini_2_flash": {
        "internal_model_id": "gemini_2_flash",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "gemini_2_flash_thinking": {
        "internal_model_id": "gemini_2_flash_thinking",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "True"
    },
    "gemini_2_pro": {
        "internal_model_id": "gemini_2_pro",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "gemini_flash_1.5_8b": {
        "internal_model_id": "gemini_flash_1.5_8b",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "gemini_flash_1.5": {
        "internal_model_id": "gemini_flash_1.5",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "gemini_learnlm_1.5": {
        "internal_model_id": "gemini_learnlm_1.5",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "gemini_pro_1.0": {
        "internal_model_id": "gemini_pro_1.0",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "gemini_pro_1.5": {
        "internal_model_id": "gemini_pro_1.5",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "gemma2_27b": {
        "internal_model_id": "google/gemma-2-27b-it",
        "hf_model_id": "google/gemma-2-27b",
        "hf_model_url": "https://huggingface.co/google/gemma-2-27b-it",
        "open / closed source": "Open",
        "parameter count": "27,000,000,000",
        "is a reasoning model?": "False"
    },
    "gemma2_2b": {
        "internal_model_id": "gemma2_2b",
        "hf_model_id": "google/gemma-2-27b-it",
        "hf_model_url": "https://huggingface.co/google/gemma-2-27b-it",
        "open / closed source": "Open",
        "parameter count": "2,000,000,000",
        "is a reasoning model?": "False"
    },
    "gemma2_9b": {
        "internal_model_id": "gemma2_9b",
        "hf_model_id": "google/gemma-2-9b",
        "hf_model_url": "https://huggingface.co/google/gemma-2-9b",
        "open / closed source": "Open",
        "parameter count": "9,000,000,000",
        "is a reasoning model?": "False"
    },
    "gemma_7b": {
        "internal_model_id": "gemma_7b",
        "hf_model_id": "google/gemma-7b-it",
        "hf_model_url": "https://huggingface.co/google/gemma-7b-it",
        "open / closed source": "Open",
        "parameter count": "7,000,000,000",
        "is a reasoning model?": "False"
    },
    "granite_3.1_2b": {
        "internal_model_id": "granite_3.1_2b",
        "hf_model_id": "ibm-granite/granite-3.1-2b-instruct",
        "hf_model_url": "https://huggingface.co/ibm-granite/granite-3.1-2b-instruct",
        "open / closed source": "Open",
        "parameter count": "2,000,000,000",
        "is a reasoning model?": "False"
    },
    "granite_3.1_8b": {
        "internal_model_id": "granite_3.1_8b",
        "hf_model_id": "ibm-granite/granite-3.1-8b-instruct",
        "hf_model_url": "https://huggingface.co/ibm-granite/granite-3.1-8b-instruct",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "granite_3.2_8b": {
        "internal_model_id": "granite_3.2_8b",
        "hf_model_id": "ibm-granite/granite-3.2-8b-instruct",
        "hf_model_url": "https://huggingface.co/ibm-granite/granite-3.2-8b-instruct",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "granite_3_2b": {
        "internal_model_id": "granite_3_2b",
        "hf_model_id": "ibm-granite/granite-3.0-2b-instruct",
        "hf_model_url": "https://huggingface.co/ibm-granite/granite-3.0-2b-instruct",
        "open / closed source": "Open",
        "parameter count": "2,000,000,000",
        "is a reasoning model?": "False"
    },
    "granite_3_8b": {
        "internal_model_id": "granite_3_8b",
        "hf_model_id": "ibm-granite/granite-3.0-8b-instruct",
        "hf_model_url": "https://huggingface.co/ibm-granite/granite-3.0-8b-instruct",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "llama_2_13b": {
        "internal_model_id": "llama_2_13b",
        "hf_model_id": "meta-llama/Llama-2-13b",
        "hf_model_url": "https://huggingface.co/meta-llama/Llama-2-13b",
        "open / closed source": "Open",
        "parameter count": "13,000,000,000",
        "is a reasoning model?": "False"
    },
    "llama_31_8b": {
        "internal_model_id": "llama_31_8b",
        "hf_model_id": "meta-llama/Llama-3.1-8B-Instruct",
        "hf_model_url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "llama_32_1b": {
        "internal_model_id": "llama_32_1b",
        "hf_model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "hf_model_url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "open / closed source": "Open",
        "parameter count": "1,000,000,000",
        "is a reasoning model?": "False"
    },
    "llama_32_3b": {
        "internal_model_id": "llama_32_3b",
        "hf_model_id": "meta-llama/Llama-3.2-3B-Instruct",
        "hf_model_url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
        "open / closed source": "Open",
        "parameter count": "3,000,000,000",
        "is a reasoning model?": "False"
    },
    "llama_3_8b": {
        "internal_model_id": "llama_3_8b",
        "hf_model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
        "hf_model_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "minimistral_3b": {
        "internal_model_id": "minimistral_3b",
        "hf_model_id": "ministral/Ministral-3b-instruct",
        "hf_model_url": "https://huggingface.co/ministral/Ministral-3b-instruct",
        "open / closed source": "Open",
        "parameter count": "3,000,000,000",
        "is a reasoning model?": "False"
    },
    "minimistral_8b": {
        "internal_model_id": "minimistral_8b",
        "hf_model_id": "mistralai/Ministral-8B-Instruct-2410",
        "hf_model_url": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "mistral_7b": {
        "internal_model_id": "mistral_7b",
        "hf_model_id": "mistralai/Mistral-7B-Instruct-v0.3",
        "hf_model_url": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3",
        "open / closed source": "Open",
        "parameter count": "7,000,000,000",
        "is a reasoning model?": "False"
    },
    "mistral_large": {
        "internal_model_id": "mistral_large",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "mistral_medium": {
        "internal_model_id": "mistral_medium",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "mistral_nemo": {
        "internal_model_id": "mistral_nemo",
        "hf_model_id": "mistralai/Mistral-Nemo-Instruct-2407",
        "hf_model_url": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
        "open / closed source": "Open",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "mistral_nemo_12b": {
        "internal_model_id": "mistral_nemo_12b",
        "hf_model_id": "nvidia/Mistral-NeMo-12B-Instruct",
        "hf_model_url": "https://huggingface.co/nvidia/Mistral-NeMo-12B-Instruct",
        "open / closed source": "Open",
        "parameter count": "12,000,000,000",
        "is a reasoning model?": "False"
    },
    "mistral_saba": {
        "internal_model_id": "mistral_saba",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "24,000,000,000",
        "is a reasoning model?": "False"
    },
    "mistral_small": {
        "internal_model_id": "mistral_small",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "mixtral_8x22b": {
        "internal_model_id": "mixtral_8x22b",
        "hf_model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
        "hf_model_url": "https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1",
        "open / closed source": "Open",
        "parameter count": "141,000,000,000",
        "is a reasoning model?": "False"
    },
    "mixtral_8x7b": {
        "internal_model_id": "mixtral_8x7b",
        "hf_model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "hf_model_url": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
        "open / closed source": "Open",
        "parameter count": "46,700,000,000",
        "is a reasoning model?": "False"
    },
    "nemotron_mini_4b": {
        "internal_model_id": "nemotron_mini_4b",
        "hf_model_id": "nvidia/Nemotron-Mini-4B-Instruct",
        "hf_model_url": "https://huggingface.co/nvidia/Nemotron-Mini-4B-Instruct",
        "open / closed source": "Open",
        "parameter count": "4,000,000,000",
        "is a reasoning model?": "False"
    },
    "nvidia_chatqa_8b": {
        "internal_model_id": "nvidia_chatqa_8b",
        "hf_model_id": "nvidia/Llama3-ChatQA-1.5-8B",
        "hf_model_url": "https://huggingface.co/nvidia/Llama3-ChatQA-1.5-8B",
        "open / closed source": "Open",
        "parameter count": "8,000,000,000",
        "is a reasoning model?": "False"
    },
    "openai_gpt_3.5_turbo": {
        "internal_model_id": "openai_gpt_3.5_turbo",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "openai_gpt_4o_mini": {
        "internal_model_id": "openai_gpt_4o_mini",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "openai_gpt_4o": {
        "internal_model_id": "openai_gpt_4o",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "openai_gpt_4": {
        "internal_model_id": "openai_gpt_4",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "openai_gpt_4_turbo": {
        "internal_model_id": "openai_gpt_4_turbo",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "False"
    },
    "openai_gpt_o1_mini": {
        "internal_model_id": "openai_gpt_o1_mini",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "True"
    },
    "openai_gpt_o1": {
        "internal_model_id": "openai_gpt_o1",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "True"
    },
    "openai_gpt_o3_mini": {
        "internal_model_id": "openai_gpt_o3_mini",
        "hf_model_id": "N/A",
        "hf_model_url": "N/A",
        "open / closed source": "Closed",
        "parameter count": "N/A",
        "is a reasoning model?": "True"
    },
    "phi_4_14b": {
        "internal_model_id": "phi_4_14b",
        "hf_model_id": "microsoft/phi-4",
        "hf_model_url": "https://huggingface.co/microsoft/phi-4",
        "open / closed source": "Open",
        "parameter count": "14,700,000,000",
        "is a reasoning model?": "False"
    },
    "qwen_2.5_14b": {
        "internal_model_id": "qwen_2.5_14b",
        "hf_model_id": "Qwen/Qwen2.5-14B-Instruct",
        "hf_model_url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct",
        "open / closed source": "Open",
        "parameter count": "14,000,000,000",
        "is a reasoning model?": "False"
    },
    "qwen_2.5_32b": {
        "internal_model_id": "qwen_2.5_32b",
        "hf_model_id": "Qwen/Qwen2.5-32B-Instruct",
        "hf_model_url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct",
        "open / closed source": "Open",
        "parameter count": "32,000,000,000",
        "is a reasoning model?": "False"
    },
    "qwen_2.5_3b": {
        "internal_model_id": "qwen_2.5_3b",
        "hf_model_id": "Qwen/Qwen2.5-3B-Instruct",
        "hf_model_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "open / closed source": "Open",
        "parameter count": "3,000,000,000",
        "is a reasoning model?": "False"
    },
    "qwen_2.5_7b": {
        "internal_model_id": "qwen_2.5_7b",
        "hf_model_id": "Qwen/Qwen2.5-7B-Instruct",
        "hf_model_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "open / closed source": "Open",
        "parameter count": "7,000,000,000",
        "is a reasoning model?": "False"
    },
    "qwen_2_1.5b": {
        "internal_model_id": "qwen_2_1.5b",
        "hf_model_id": "Qwen/Qwen2-1.5B-Instruct",
        "hf_model_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct",
        "open / closed source": "Open",
        "parameter count": "1,500,000,000",
        "is a reasoning model?": "False"
    },
    "qwen_32b": {
        "internal_model_id": "qwen_32b",
        "hf_model_id": "Qwen/Qwen1.5-32B",
        "hf_model_url": "https://huggingface.co/Qwen/Qwen1.5-32B",
        "open / closed source": "Open",
        "parameter count": "32,000,000,000",
        "is a reasoning model?": "False"
    },
    "qwen_7b": {
        "internal_model_id": "qwen_7b",
        "hf_model_id": "Qwen/Qwen-7B-Chat",
        "hf_model_url": "https://huggingface.co/Qwen/Qwen-7B-Chat",
        "open / closed source": "Open",
        "parameter count": "7,000,000,000",
        "is a reasoning model?": "False"
    },
    "vicuna_13b": {
        "internal_model_id": "vicuna_13b",
        "hf_model_id": "lmsys/vicuna-13b-v1.5",
        "hf_model_url": "https://huggingface.co/lmsys/vicuna-13b-v1.5",
        "open / closed source": "Open",
        "parameter count": "13,000,000,000",
        "is a reasoning model?": "False"
    },
    "vicuna_7b": {
        "internal_model_id": "vicuna_7b",
        "hf_model_id": "lmsys/vicuna-7b-v1.5",
        "hf_model_url": "https://huggingface.co/lmsys/vicuna-7b-v1.5",
        "open / closed source": "Open",
        "parameter count": "7,000,000,000",
        "is a reasoning model?": "False"
    }
}