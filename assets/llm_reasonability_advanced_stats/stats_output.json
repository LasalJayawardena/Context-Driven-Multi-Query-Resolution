{
    "Don't give me the value in terms of the model parameters/features, give me the data value.": {
        "95%_CI_margin": 0.47114144465284014,
        "average": 6.885714285714286,
        "count": 70,
        "impartial_models": [
            "deepseek_qwen_7b",
            "falcon3_7b",
            "gemma2_9b",
            "llama_3_8b",
            "mistral_nemo",
            "mixtral_8x22b",
            "nvidia_chatqa_8b",
            "openai_gpt_4_turbo",
            "openai_gpt_4o_mini",
            "qwen_7b"
        ],
        "median": 7.0,
        "std_dev": 2.0111490489007546,
        "variance": 4.04472049689441
    },
    "Explain how the above was geenrated and what it tells us": {
        "95%_CI_margin": 0.15914335894297374,
        "average": 8.728571428571428,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_llama_8b",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_32b",
            "deepseek_qwen_7b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_flash_1.5",
            "gemini_learnlm_1.5",
            "gemini_pro_1.0",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "granite_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_7b",
            "mistral_large",
            "mistral_medium",
            "mixtral_8x22b",
            "mixtral_8x7b",
            "nemotron_mini_4b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_7b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 9.0,
        "std_dev": 0.6793310556936242,
        "variance": 0.46149068322981385
    },
    "Explain hwo the expmantion was generated": {
        "95%_CI_margin": 0.1672289067307946,
        "average": 8.535714285714286,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3_haiku",
            "deepseek_llama_8b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_pro",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3_2b",
            "granite_3_8b",
            "llama_31_8b",
            "llama_32_1b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "mistral_7b",
            "mistral_large",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x22b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4o_mini",
            "qwen_2.5_32b",
            "qwen_2_1.5b",
            "vicuna_13b",
            "vicuna_7b"
        ],
        "median": 8.25,
        "std_dev": 0.7138456201155667,
        "variance": 0.509575569358178
    },
    "Explain whats shown in the image above": {
        "95%_CI_margin": 0.1691324153231529,
        "average": 8.714285714285714,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "deepseek_qwen_14b",
            "deepseek_qwen_32b",
            "falcon3_10b",
            "falcon3_3b",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_learnlm_1.5",
            "gemini_pro_1.0",
            "gemma2_27b",
            "gemma_7b",
            "granite_3_8b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x22b",
            "nemotron_mini_4b",
            "openai_gpt_o1",
            "openai_gpt_o3_mini",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 9.0,
        "std_dev": 0.7219710770002111,
        "variance": 0.5212422360248448
    },
    "How can a loan application be decided based on the amount that you've paid back on the loan? That doesn't make any logical sense.": {
        "95%_CI_margin": 0.2383756626036709,
        "average": 7.671428571428572,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_14b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemma2_27b",
            "gemma_7b",
            "granite_3.1_2b",
            "granite_3.2_8b",
            "granite_3_2b",
            "granite_3_8b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_1b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_small",
            "mixtral_8x22b",
            "openai_gpt_4_turbo",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_7b",
            "qwen_2_1.5b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 8.0,
        "std_dev": 1.0175478989748221,
        "variance": 1.0354037267080747
    },
    "How did you come to this conclusion": {
        "95%_CI_margin": 0.17081064352676908,
        "average": 8.49,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_sonnet",
            "deepseek_llama_8b",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_32b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_pro_1.5",
            "gemma2_2b",
            "gemma2_9b",
            "llama_32_1b",
            "mistral_7b",
            "mistral_large",
            "mistral_medium",
            "mixtral_8x7b",
            "nemotron_mini_4b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_7b",
            "qwen_32b"
        ],
        "median": 8.75,
        "std_dev": 0.729134885435761,
        "variance": 0.5316376811594202
    },
    "How reliable is this prediction?": {
        "95%_CI_margin": 0.22143000333471433,
        "average": 8.192857142857143,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_sonnet",
            "deepseek_llama_8b",
            "deepseek_qwen_32b",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_flash_1.5",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "llama_2_13b",
            "llama_32_1b",
            "mistral_7b",
            "mistral_large",
            "mistral_medium",
            "mistral_nemo_12b",
            "mistral_small",
            "mixtral_8x22b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2_1.5b",
            "qwen_32b"
        ],
        "median": 8.0,
        "std_dev": 0.945212410538074,
        "variance": 0.8934265010351966
    },
    "I didn't understand the description, only the details": {
        "95%_CI_margin": 0.2084727070031408,
        "average": 8.071428571428571,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_llama_8b",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_pro_1.0",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3.2_8b",
            "granite_3_8b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_1b",
            "llama_32_3b",
            "minimistral_3b",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x7b",
            "openai_gpt_4o",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_32b",
            "vicuna_7b"
        ],
        "median": 8.0,
        "std_dev": 0.8899019416983589,
        "variance": 0.7919254658385094
    },
    "I need a table of all other alternatives explainers that could be used instead of this": {
        "95%_CI_margin": 0.17257067445298876,
        "average": 8.67142857142857,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_sonnet",
            "deepseek_llama_8b",
            "deepseek_qwen_14b",
            "deepseek_qwen_32b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_flash_1.5",
            "gemini_learnlm_1.5",
            "gemini_pro_1.5",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3.2_8b",
            "granite_3_2b",
            "minimistral_3b",
            "mistral_7b",
            "mistral_large",
            "mistral_medium",
            "mistral_nemo",
            "mistral_small",
            "mixtral_8x22b",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_32b"
        ],
        "median": 9.0,
        "std_dev": 0.7366478829940861,
        "variance": 0.5426501035196688
    },
    "I still don't understand what the sensor is measuring. What is the picture of?": {
        "95%_CI_margin": 0.29209527927358403,
        "average": 7.557142857142857,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_llama_8b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_pro",
            "gemini_flash_1.5_8b",
            "gemma_7b",
            "granite_3.1_2b",
            "granite_3.2_8b",
            "granite_3_8b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_7b",
            "mistral_large",
            "mistral_medium",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_small",
            "mixtral_8x7b",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o3_mini",
            "qwen_32b"
        ],
        "median": 8.0,
        "std_dev": 1.2468594087118114,
        "variance": 1.554658385093168
    },
    "Please elaborate": {
        "95%_CI_margin": 0.23167993914644086,
        "average": 8.514285714285714,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_14b",
            "deepseek_qwen_32b",
            "falcon3_10b",
            "falcon3_3b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_learnlm_1.5",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_medium",
            "mixtral_8x22b",
            "mixtral_8x7b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_7b",
            "qwen_32b"
        ],
        "median": 9.0,
        "std_dev": 0.9889660409881338,
        "variance": 0.9780538302277432
    },
    "What are the numbers in brackets in the third row? And can you improve the clarity of the explanation description?": {
        "95%_CI_margin": 0.21481437892120803,
        "average": 8.321428571428571,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3_haiku",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_14b",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_flash_1.5_8b",
            "gemini_pro_1.0",
            "gemma2_27b",
            "gemma2_2b",
            "gemma_7b",
            "granite_3.1_2b",
            "granite_3.1_8b",
            "granite_3.2_8b",
            "granite_3_2b",
            "granite_3_8b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_1b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mixtral_8x7b",
            "phi_4_14b",
            "qwen_2_1.5b",
            "qwen_32b",
            "vicuna_7b"
        ],
        "median": 8.0,
        "std_dev": 0.9169724692250963,
        "variance": 0.8408385093167702
    },
    "What is fluidity": {
        "95%_CI_margin": 0.18242870356404436,
        "average": 7.871428571428571,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.1",
            "anthropic_claude_3_haiku",
            "deepseek_qwen_32b",
            "falcon3_10b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_learnlm_1.5",
            "gemini_pro_1.0",
            "gemma2_9b",
            "gemma_7b",
            "granite_3.1_2b",
            "granite_3.1_8b",
            "granite_3.2_8b",
            "granite_3_2b",
            "llama_31_8b",
            "llama_32_1b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_nemo",
            "mistral_small",
            "mixtral_8x22b",
            "mixtral_8x7b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o_mini",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_7b",
            "qwen_2_1.5b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 8.0,
        "std_dev": 0.778728591655461,
        "variance": 0.6064182194616978
    },
    "What is the mat behind it": {
        "95%_CI_margin": 0.46165555890995585,
        "average": 6.935714285714286,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_14b",
            "deepseek_v2_16b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_thinking",
            "gemma2_2b",
            "gemma_7b",
            "granite_3.1_8b",
            "granite_3.2_8b",
            "granite_3_2b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_7b",
            "mistral_nemo_12b",
            "mixtral_8x7b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4_turbo",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "qwen_2_1.5b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 8.0,
        "std_dev": 1.9706568988122815,
        "variance": 3.8834886128364388
    },
    "can you propose alternative explanation method ?": {
        "95%_CI_margin": 0.1922023390347651,
        "average": 8.607142857142858,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_14b",
            "deepseek_qwen_32b",
            "deepseek_qwen_7b",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_learnlm_1.5",
            "gemini_pro_1.5",
            "gemma2_27b",
            "granite_3_2b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_7b",
            "mistral_large",
            "mistral_medium",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x22b",
            "nemotron_mini_4b",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_32b"
        ],
        "median": 9.0,
        "std_dev": 0.8204490514119284,
        "variance": 0.673136645962733
    },
    "explain how integrated gradients work in very simple terms": {
        "95%_CI_margin": 0.21629033091281913,
        "average": 8.42142857142857,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_32b",
            "deepseek_qwen_7b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_learnlm_1.5",
            "gemini_pro_1.5",
            "gemma2_9b",
            "llama_2_13b",
            "llama_32_3b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x7b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1_mini",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2_1.5b"
        ],
        "median": 8.0,
        "std_dev": 0.9232728265335879,
        "variance": 0.8524327122153207
    },
    "explain me what the image above mean": {
        "95%_CI_margin": 0.1564793823525939,
        "average": 8.714285714285714,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_14b",
            "deepseek_qwen_32b",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_pro_1.5",
            "granite_3_8b",
            "mistral_large",
            "mistral_medium",
            "mistral_small",
            "mixtral_8x22b",
            "mixtral_8x7b",
            "nemotron_mini_4b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "qwen_32b"
        ],
        "median": 9.0,
        "std_dev": 0.6679594091385559,
        "variance": 0.4461697722567287
    },
    "explain the metrics and how trustworty the system is": {
        "95%_CI_margin": 0.15908087451884703,
        "average": 8.278571428571428,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_flash_1.5",
            "gemini_pro_1.0",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3_8b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "nvidia_chatqa_8b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "vicuna_7b"
        ],
        "median": 8.0,
        "std_dev": 0.6790643300816455,
        "variance": 0.461128364389234
    },
    "explain what is counterfactuals with an image": {
        "95%_CI_margin": 0.28006816561563075,
        "average": 8.302857142857144,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_32b",
            "falcon3_10b",
            "gemini_flash_1.5_8b",
            "gemini_pro_1.5",
            "gemma2_9b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_o3_mini",
            "qwen_2.5_32b",
            "qwen_2.5_7b",
            "qwen_2_1.5b",
            "vicuna_13b",
            "vicuna_7b"
        ],
        "median": 8.0,
        "std_dev": 1.1955195860985892,
        "variance": 1.4292670807453418
    },
    "give me 2 other types of explanation of the result": {
        "95%_CI_margin": 0.21158340254349833,
        "average": 8.714285714285714,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_14b",
            "deepseek_qwen_32b",
            "falcon3_10b",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_pro_1.5",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "minimistral_3b",
            "mistral_large",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x22b",
            "nemotron_mini_4b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_32b"
        ],
        "median": 9.0,
        "std_dev": 0.9031804856439455,
        "variance": 0.8157349896480331
    },
    "give me insights about how lime explain that the result will be the same for similar instance": {
        "95%_CI_margin": 0.14674615764172055,
        "average": 8.45,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "deepseek_llama_8b",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_learnlm_1.5",
            "gemini_pro_1.0",
            "gemini_pro_1.5",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3_2b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "mistral_large",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "nemotron_mini_4b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "vicuna_13b",
            "vicuna_7b"
        ],
        "median": 8.0,
        "std_dev": 0.6264114497259977,
        "variance": 0.39239130434782615
    },
    "give me other explanation methods": {
        "95%_CI_margin": 0.26242525505894737,
        "average": 8.614285714285714,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_llama_8b",
            "deepseek_qwen_14b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_flash_lite",
            "gemini_flash_1.5",
            "gemini_learnlm_1.5",
            "gemini_pro_1.5",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "granite_3.1_2b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x22b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "qwen_32b"
        ],
        "median": 9.0,
        "std_dev": 1.120207759494033,
        "variance": 1.2548654244306412
    },
    "hat is the sensor measuring?": {
        "95%_CI_margin": 0.520851921987124,
        "average": 3.3142857142857145,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_sonnet",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5_8b",
            "gemma2_27b",
            "gemma2_9b",
            "llama_31_8b",
            "llama_3_8b",
            "minimistral_3b",
            "mistral_7b",
            "mistral_large",
            "mistral_small",
            "mixtral_8x22b",
            "mixtral_8x7b",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b"
        ],
        "median": 2.0,
        "std_dev": 2.2233468513779155,
        "variance": 4.9432712215320915
    },
    "how was the AI able to do this": {
        "95%_CI_margin": 0.16221938982372797,
        "average": 8.314285714285715,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_1.5b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_learnlm_1.5",
            "gemini_pro_1.0",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3.2_8b",
            "granite_3_8b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_3_8b",
            "minimistral_3b",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "nvidia_chatqa_8b",
            "openai_gpt_4o_mini",
            "phi_4_14b",
            "qwen_2.5_32b",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "qwen_2_1.5b",
            "vicuna_13b"
        ],
        "median": 8.0,
        "std_dev": 0.6924616275217438,
        "variance": 0.47950310559006215
    },
    "no": {
        "95%_CI_margin": 0.40992357011195796,
        "average": 6.8428571428571425,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_3b",
            "gemini_2_flash_lite",
            "gemini_flash_1.5_8b",
            "gemma2_27b",
            "granite_3.1_2b",
            "granite_3_2b",
            "minimistral_8b",
            "mistral_large",
            "mistral_saba",
            "mixtral_8x22b",
            "openai_gpt_4o",
            "qwen_2.5_32b",
            "qwen_2_1.5b",
            "qwen_7b"
        ],
        "median": 7.0,
        "std_dev": 1.7498299237082333,
        "variance": 3.0619047619047617
    },
    "que signifie unune influence negative sur le resultat ?": {
        "95%_CI_margin": 0.19597101234917227,
        "average": 8.714285714285714,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "deepseek_llama_8b",
            "deepseek_qwen_14b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3.1_2b",
            "llama_31_8b",
            "llama_32_1b",
            "llama_32_3b",
            "llama_3_8b",
            "mistral_nemo_12b",
            "mixtral_8x7b",
            "openai_gpt_o1_mini",
            "phi_4_14b",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 9.0,
        "std_dev": 0.836536287714123,
        "variance": 0.6997929606625259
    },
    "quelle est l'influence des mots surlignes dans l'explication ci-dessus?": {
        "95%_CI_margin": 0.18753457652204922,
        "average": 8.621428571428572,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_32b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5_8b",
            "gemini_learnlm_1.5",
            "gemma2_2b",
            "gemma2_9b",
            "granite_3_8b",
            "llama_31_8b",
            "minimistral_8b",
            "mistral_large",
            "mistral_nemo",
            "nemotron_mini_4b",
            "nvidia_chatqa_8b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "qwen_2.5_14b",
            "qwen_2.5_3b",
            "qwen_2.5_7b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 9.0,
        "std_dev": 0.8005238967805833,
        "variance": 0.64083850931677
    },
    "what do precision and recall mean, and how do they relate to the overall accuracy?": {
        "95%_CI_margin": 0.17402132136567366,
        "average": 9.05,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "falcon3_10b",
            "gemini_2_pro",
            "gemini_flash_1.5_8b",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "llama_31_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_medium",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x7b",
            "nemotron_mini_4b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o3_mini",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_32b",
            "vicuna_7b"
        ],
        "median": 9.0,
        "std_dev": 0.7428402211800991,
        "variance": 0.5518115942028985
    },
    "what do the colors mean when the result is different ?": {
        "95%_CI_margin": 0.16267403166980937,
        "average": 8.842857142857143,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_14b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_learnlm_1.5",
            "gemini_pro_1.5",
            "gemma2_9b",
            "granite_3_8b",
            "llama_32_1b",
            "llama_32_3b",
            "minimistral_3b",
            "mistral_medium",
            "mistral_small",
            "mixtral_8x22b",
            "mixtral_8x7b",
            "nemotron_mini_4b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_7b",
            "qwen_32b"
        ],
        "median": 9.0,
        "std_dev": 0.6944023451697335,
        "variance": 0.4821946169772257
    },
    "what does the measure mean ?": {
        "95%_CI_margin": 0.304591815243029,
        "average": 8.592857142857143,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_32b",
            "falcon3_10b",
            "falcon3_3b",
            "gemini_2_flash_thinking",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_large",
            "mistral_saba",
            "mistral_small",
            "mixtral_8x7b",
            "openai_gpt_3.5_turbo",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_32b"
        ],
        "median": 9.0,
        "std_dev": 1.300203041955586,
        "variance": 1.6905279503105592
    },
    "what is tf-idf here ?": {
        "95%_CI_margin": 0.21158340254349833,
        "average": 8.714285714285714,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_sonnet",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "deepseek_llama_8b",
            "falcon3_10b",
            "falcon3_7b",
            "gemini_2_flash",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_learnlm_1.5",
            "gemini_pro_1.0",
            "gemini_pro_1.5",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "granite_3.1_2b",
            "granite_3_8b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "mistral_large",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mistral_small",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "qwen_2.5_32b",
            "vicuna_13b"
        ],
        "median": 9.0,
        "std_dev": 0.9031804856439455,
        "variance": 0.8157349896480331
    },
    "what is the difference between SHAP and LIME": {
        "95%_CI_margin": 0.18952342977791062,
        "average": 9.035714285714286,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "anthropic_claude_3_opus",
            "anthropic_claude_3_sonnet",
            "deepseek_qwen_1.5b",
            "deepseek_qwen_14b",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "gemini_2_pro",
            "gemini_flash_1.5",
            "gemini_flash_1.5_8b",
            "gemini_pro_1.5",
            "gemma2_27b",
            "gemma2_2b",
            "gemma_7b",
            "llama_31_8b",
            "minimistral_3b",
            "mistral_large",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_saba",
            "mixtral_8x22b",
            "mixtral_8x7b",
            "openai_gpt_4_turbo",
            "openai_gpt_4o",
            "openai_gpt_4o_mini",
            "openai_gpt_o1",
            "openai_gpt_o1_mini",
            "openai_gpt_o3_mini",
            "qwen_2.5_14b",
            "qwen_2.5_32b",
            "qwen_2.5_7b"
        ],
        "median": 9.0,
        "std_dev": 0.8090136621776312,
        "variance": 0.6545031055900623
    },
    "what other explanation do you suggest for my use case ?": {
        "95%_CI_margin": 0.2480520048325537,
        "average": 8.335714285714285,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_2.0",
            "anthropic_claude_2.1",
            "anthropic_claude_3.5_haiku",
            "anthropic_claude_3_haiku",
            "deepseek_llama_8b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_3b",
            "gemini_2_flash",
            "gemini_2_flash_lite",
            "gemini_2_flash_thinking",
            "gemini_flash_1.5_8b",
            "gemini_pro_1.0",
            "gemini_pro_1.5",
            "gemma2_27b",
            "gemma2_2b",
            "gemma_7b",
            "llama_2_13b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_8b",
            "mistral_nemo",
            "mistral_nemo_12b",
            "mistral_small",
            "nvidia_chatqa_8b",
            "openai_gpt_4",
            "openai_gpt_4o",
            "vicuna_7b"
        ],
        "median": 8.0,
        "std_dev": 1.058853045637934,
        "variance": 1.1211697722567286
    },
    "what other way of explaining could I use ?": {
        "95%_CI_margin": 0.19027135466432432,
        "average": 8.678571428571429,
        "count": 70,
        "impartial_models": [
            "anthropic_claude_3_haiku",
            "deepseek_qwen_14b",
            "deepseek_qwen_7b",
            "deepseek_v2_16b",
            "falcon3_10b",
            "falcon3_3b",
            "falcon3_7b",
            "gemini_learnlm_1.5",
            "gemini_pro_1.0",
            "gemma2_27b",
            "gemma2_2b",
            "gemma2_9b",
            "gemma_7b",
            "granite_3.1_8b",
            "granite_3_8b",
            "llama_31_8b",
            "llama_32_3b",
            "llama_3_8b",
            "minimistral_3b",
            "minimistral_8b",
            "mistral_nemo_12b",
            "mistral_saba",
            "mixtral_8x7b",
            "openai_gpt_o1",
            "openai_gpt_o3_mini",
            "phi_4_14b",
            "qwen_2.5_14b",
            "qwen_2.5_7b",
            "qwen_32b",
            "vicuna_13b"
        ],
        "median": 9.0,
        "std_dev": 0.8122063093986127,
        "variance": 0.659679089026915
    }
}